{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'afm_op'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytlsd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lsd\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mafm_op\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m afm\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytlsd'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run the homography adaptation for all images in a given folder\n",
    "to regress and aggregate line distance function maps.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pytlsd import lsd\n",
    "from afm_op import afm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from ..datasets.utils.homographies import sample_homography, warp_lines\n",
    "from ..datasets.utils.data_augmentation import random_contrast\n",
    "\n",
    "\n",
    "homography_params = {\n",
    "}\n",
    "\n",
    "\n",
    "def ha_df(img, num=100, border_margin=3, min_counts=5):\n",
    "    \"\"\" Perform homography adaptation to regress line distance function maps.\n",
    "    Args:\n",
    "        img: a grayscale np image.\n",
    "        num: number of homographies used during HA.\n",
    "        border_margin: margin used to erode the boundaries of the mask.\n",
    "        min_counts: any pixel which is not activated by more than min_count is BG.\n",
    "    Returns:\n",
    "        The aggregated distance function maps in pixels\n",
    "        and the angle to the closest line.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    size = (w, h)\n",
    "    df_maps, angles, closests, counts = [], [], [], []\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n",
    "                                       (border_margin * 2, border_margin * 2))\n",
    "    pix_loc = np.stack(np.meshgrid(np.arange(h), np.arange(w), indexing='ij'),\n",
    "                       axis=-1)\n",
    "    raster_lines = np.zeros_like(img)\n",
    "\n",
    "    # Loop through all the homographies\n",
    "    for i in range(num):\n",
    "        # Generate a random homography\n",
    "        if i == 0:\n",
    "            H = np.eye(3)\n",
    "        else:\n",
    "            H = sample_homography(img.shape, **homography_params)\n",
    "        H_inv = np.linalg.inv(H)\n",
    "        \n",
    "        # Warp the image\n",
    "        warped_img = cv2.warpPerspective(img, H, size,\n",
    "                                         borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        # Regress the DF on the warped image\n",
    "        warped_lines = lsd(warped_img)[:, [1, 0, 3, 2]].reshape(-1, 2, 2)\n",
    "        \n",
    "        # Warp the lines back\n",
    "        lines = warp_lines(warped_lines, H_inv)\n",
    "        \n",
    "        # Get the DF and angles\n",
    "        num_lines = len(lines)\n",
    "        cuda_lines = torch.from_numpy(lines[:, :, [1, 0]].astype(np.float32))\n",
    "        cuda_lines = cuda_lines.reshape(-1, 4)[None].cuda()\n",
    "        offset = afm(\n",
    "            cuda_lines,\n",
    "            torch.IntTensor([[0, num_lines, h, w]]).cuda(), h, w)[0]\n",
    "        offset = offset[0].permute(1, 2, 0).cpu().numpy()[:, :, [1, 0]]\n",
    "        closest = pix_loc + offset\n",
    "        df = np.linalg.norm(offset, axis=-1)\n",
    "        angle = np.mod(np.arctan2(\n",
    "            offset[:, :, 0], offset[:, :, 1]) + np.pi / 2, np.pi)\n",
    "        \n",
    "        df_maps.append(df)\n",
    "        angles.append(angle)\n",
    "        closests.append(closest)\n",
    "        \n",
    "        # Compute the valid pixels\n",
    "        count = cv2.warpPerspective(np.ones_like(img), H_inv, size,\n",
    "                                    flags=cv2.INTER_NEAREST)\n",
    "        count = cv2.erode(count, kernel)\n",
    "        counts.append(count)\n",
    "        raster_lines += (df < 1).astype(np.uint8) * count \n",
    "        \n",
    "    # Compute the median of all DF maps, with counts as weights\n",
    "    df_maps, angles = np.stack(df_maps), np.stack(angles)\n",
    "    counts, closests = np.stack(counts), np.stack(closests)\n",
    "    \n",
    "    # Median of the DF\n",
    "    df_maps[counts == 0] = np.nan\n",
    "    avg_df = np.nanmedian(df_maps, axis=0)\n",
    "\n",
    "    # Median of the closest\n",
    "    closests[counts == 0] = np.nan\n",
    "    avg_closest = np.nanmedian(closests, axis=0)\n",
    "\n",
    "    # Median of the angle\n",
    "    circ_bound = (np.minimum(np.pi - angles, angles)\n",
    "                  * counts).sum(0) / counts.sum(0) < 0.3\n",
    "    angles[:, circ_bound] -= np.where(\n",
    "        angles[:, circ_bound] > np.pi /2,\n",
    "        np.ones_like(angles[:, circ_bound]) * np.pi,\n",
    "        np.zeros_like(angles[:, circ_bound]))\n",
    "    angles[counts == 0] = np.nan\n",
    "    avg_angle = np.mod(np.nanmedian(angles, axis=0), np.pi)\n",
    "\n",
    "    # Generate the background mask and a saliency score\n",
    "    raster_lines = np.where(raster_lines > min_counts, np.ones_like(img),\n",
    "                            np.zeros_like(img))\n",
    "    raster_lines = cv2.dilate(raster_lines, np.ones((21, 21), dtype=np.uint8))\n",
    "    bg_mask = (1 - raster_lines).astype(float)\n",
    "\n",
    "    return avg_df, avg_angle, avg_closest[:, :, [1, 0]], bg_mask\n",
    "\n",
    "\n",
    "def process_image(img_path, randomize_contrast, num_H, output_folder):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    if randomize_contrast is not None:\n",
    "        img = randomize_contrast(img)\n",
    "    \n",
    "    # Run homography adaptation\n",
    "    df, angle, closest, bg_mask = ha_df(img, num=num_H)\n",
    "\n",
    "    # Save the DF in a hdf5 file\n",
    "    out_path = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(output_folder, out_path) + '.hdf5'\n",
    "    with h5py.File(out_path, \"w\") as f:\n",
    "        f.create_dataset(\"df\", data=df.flatten())\n",
    "        f.create_dataset(\"line_level\", data=angle.flatten())\n",
    "        f.create_dataset(\"closest\", data=closest.flatten())\n",
    "        f.create_dataset(\"bg_mask\", data=bg_mask.flatten())\n",
    "\n",
    "\n",
    "def export_ha(images_list, output_folder, num_H=100,\n",
    "              rdm_contrast=False, n_jobs=1):\n",
    "    # Parse the data\n",
    "    with open(images_list, 'r') as f:\n",
    "        image_files = f.readlines()\n",
    "    image_files = [path.strip('\\n') for path in image_files]\n",
    "    \n",
    "    # Random contrast object\n",
    "    randomize_contrast = random_contrast() if rdm_contrast else None\n",
    "    \n",
    "    # Process each image in parallel\n",
    "    Parallel(n_jobs=n_jobs, backend='multiprocessing')(delayed(process_image)(\n",
    "        img_path, randomize_contrast, num_H, output_folder)\n",
    "                                            for img_path in tqdm(image_files))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('images_list', type=str,\n",
    "                        help='Path to a txt file containing the image paths.')\n",
    "    parser.add_argument('output_folder', type=str, help='Output folder.')\n",
    "    parser.add_argument('--num_H', type=int, default=100,\n",
    "                        help='Number of homographies used during HA.')\n",
    "    parser.add_argument('--random_contrast', action='store_true',\n",
    "                        help='Add random contrast to the images (disabled by default).')\n",
    "    parser.add_argument('--n_jobs', type=int, default=1,\n",
    "                        help='Number of jobs to run in parallel.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    export_ha(args.images_list, args.output_folder, args.num_H,\n",
    "              args.random_contrast, args.n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2D visualization primitives based on Matplotlib.\n",
    "\n",
    "1) Plot images with `plot_images`.\n",
    "2) Call `plot_keypoints` or `plot_matches` any number of times.\n",
    "3) Optionally: save a .png or .pdf plot (nice in papers!) with `save_plot`.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import flow_vis\n",
    "\n",
    "\n",
    "def cm_RdGn(x):\n",
    "    \"\"\"Custom colormap: red (0) -> yellow (0.5) -> green (1).\"\"\"\n",
    "    x = np.clip(x, 0, 1)[..., None]*2\n",
    "    c = x*np.array([[0, 1., 0]]) + (2-x)*np.array([[1., 0, 0]])\n",
    "    return np.clip(c, 0, 1)\n",
    "\n",
    "\n",
    "def plot_images(imgs, titles=None, cmaps='gray', dpi=100, size=6, pad=.5):\n",
    "    \"\"\"Plot a set of images horizontally.\n",
    "    Args:\n",
    "        imgs: a list of NumPy or PyTorch images, RGB (H, W, 3) or mono (H, W).\n",
    "        titles: a list of strings, as titles for each image.\n",
    "        cmaps: colormaps for monochrome images.\n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    if not isinstance(cmaps, (list, tuple)):\n",
    "        cmaps = [cmaps] * n\n",
    "    figsize = (size*n, size*3/4) if size is not None else None\n",
    "    fig, ax = plt.subplots(1, n, figsize=figsize, dpi=dpi)\n",
    "    if n == 1:\n",
    "        ax = [ax]\n",
    "    for i in range(n):\n",
    "        ax[i].imshow(imgs[i], cmap=plt.get_cmap(cmaps[i]))\n",
    "        ax[i].get_yaxis().set_ticks([])\n",
    "        ax[i].get_xaxis().set_ticks([])\n",
    "        ax[i].set_axis_off()\n",
    "        for spine in ax[i].spines.values():  # remove frame\n",
    "            spine.set_visible(False)\n",
    "        if titles:\n",
    "            ax[i].set_title(titles[i])\n",
    "    fig.tight_layout(pad=pad)\n",
    "        \n",
    "        \n",
    "def plot_lines(lines, line_colors='orange', point_color='cyan',\n",
    "               ps=4, lw=2, indices=(0, 1), alpha=1):\n",
    "    \"\"\" Plot lines and endpoints for existing images.\n",
    "    Args:\n",
    "        lines: list of ndarrays of size (N, 2, 2).\n",
    "        line_colors: string, or list of list of tuples (one for per line).\n",
    "        point_color: unique color for all endpoints.\n",
    "        ps: size of the keypoints as float pixels.\n",
    "        lw: line width as float pixels.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "        alpha: alpha transparency.\n",
    "    \"\"\"\n",
    "    if not isinstance(line_colors, list):\n",
    "        line_colors = [[line_colors] * len(l) for l in lines]\n",
    "    for i in range(len(lines)):\n",
    "        if ((not isinstance(line_colors[i], list))\n",
    "            and (not isinstance(line_colors[i], np.ndarray))):\n",
    "            line_colors[i] = [line_colors[i]] * len(lines[i])\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    axes = [ax[i] for i in indices]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Plot the lines and junctions\n",
    "    for a, l, lc in zip(axes, lines, line_colors):\n",
    "        for i in range(len(l)):\n",
    "            line = matplotlib.lines.Line2D(\n",
    "                (l[i, 0, 0], l[i, 1, 0]), (l[i, 0, 1], l[i, 1, 1]),\n",
    "                zorder=1, c=lc[i], linewidth=lw, alpha=alpha)\n",
    "            a.add_line(line)\n",
    "        pts = l.reshape(-1, 2)\n",
    "        a.scatter(pts[:, 0], pts[:, 1], c=point_color, s=ps,\n",
    "                  linewidths=0, zorder=2, alpha=alpha)\n",
    "\n",
    "        \n",
    "def plot_vp(lines, vp_labels, lw=2, indices=(0, 1)):\n",
    "    \"\"\" Plot the vanishing directions of the lines, given the vp labels.\n",
    "    Lines labelled with -1 are ignored.\n",
    "    Args:\n",
    "        lines: list of ndarrays of size (N, 2, 2).\n",
    "        vp_labels: list of labels indicating the corresponding vp.\n",
    "        lw: line width as float pixels.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "    \"\"\"\n",
    "    num_labels = np.amax([np.amax(vp) for vp in vp_labels if len(vp) > 0]) + 1\n",
    "    colors = sns.color_palette(\"hls\", num_labels)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    axes = [ax[i] for i in indices]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Plot the lines and junctions\n",
    "    for a, l, vp in zip(axes, lines, vp_labels):\n",
    "        for i in range(len(l)):\n",
    "            if vp[i] == -1:\n",
    "                continue\n",
    "            line = matplotlib.lines.Line2D(\n",
    "                (l[i, 0, 0], l[i, 1, 0]), (l[i, 0, 1], l[i, 1, 1]),\n",
    "                zorder=1, c=colors[vp[i]], linewidth=lw)\n",
    "            a.add_line(line)\n",
    "\n",
    "\n",
    "def plot_color_line_matches(lines, correct_matches=None,\n",
    "                            lw=2, indices=(0, 1)):\n",
    "    \"\"\"Plot line matches for existing images with multiple colors.\n",
    "    Args:\n",
    "        lines: list of ndarrays of size (N, 2, 2).\n",
    "        correct_matches: bool array of size (N,) indicating correct matches.\n",
    "        lw: line width as float pixels.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "    \"\"\"\n",
    "    n_lines = len(lines[0])\n",
    "    colors = sns.color_palette('husl', n_colors=n_lines)\n",
    "    np.random.shuffle(colors)\n",
    "    alphas = np.ones(n_lines)\n",
    "    # If correct_matches is not None, display wrong matches with a low alpha\n",
    "    if correct_matches is not None:\n",
    "        alphas[~np.array(correct_matches)] = 0.2\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    axes = [ax[i] for i in indices]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Plot the lines\n",
    "    for a, l in zip(axes, lines):\n",
    "        # Transform the points into the figure coordinate system\n",
    "        transFigure = fig.transFigure.inverted()\n",
    "        endpoint0 = transFigure.transform(a.transData.transform(l[:, 0]))\n",
    "        endpoint1 = transFigure.transform(a.transData.transform(l[:, 1]))\n",
    "        fig.lines += [matplotlib.lines.Line2D(\n",
    "            (endpoint0[i, 0], endpoint1[i, 0]),\n",
    "            (endpoint0[i, 1], endpoint1[i, 1]),\n",
    "            zorder=1, transform=fig.transFigure, c=colors[i],\n",
    "            alpha=alphas[i], linewidth=lw) for i in range(n_lines)]\n",
    "\n",
    "\n",
    "def plot_color_lines(lines, correct_matches, wrong_matches,\n",
    "                     lw=2, indices=(0, 1)):\n",
    "    \"\"\"Plot line matches for existing images with multiple colors:\n",
    "    green for correct matches, red for wrong ones, and blue for the rest.\n",
    "    Args:\n",
    "        lines: list of ndarrays of size (N, 2, 2).\n",
    "        correct_matches: list of bool arrays of size N with correct matches.\n",
    "        wrong_matches: list of bool arrays of size (N,) with correct matches.\n",
    "        lw: line width as float pixels.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "    \"\"\"\n",
    "    # palette = sns.color_palette()\n",
    "    palette = sns.color_palette(\"hls\", 8)\n",
    "    blue = palette[5]  # palette[0]\n",
    "    red = palette[0]  # palette[3]\n",
    "    green = palette[2]  # palette[2]\n",
    "    colors = [np.array([blue] * len(l)) for l in lines]\n",
    "    for i, c in enumerate(colors):\n",
    "        c[np.array(correct_matches[i])] = green\n",
    "        c[np.array(wrong_matches[i])] = red\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    axes = [ax[i] for i in indices]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Plot the lines\n",
    "    for a, l, c in zip(axes, lines, colors):\n",
    "        # Transform the points into the figure coordinate system\n",
    "        transFigure = fig.transFigure.inverted()\n",
    "        endpoint0 = transFigure.transform(a.transData.transform(l[:, 0]))\n",
    "        endpoint1 = transFigure.transform(a.transData.transform(l[:, 1]))\n",
    "        fig.lines += [matplotlib.lines.Line2D(\n",
    "            (endpoint0[i, 0], endpoint1[i, 0]),\n",
    "            (endpoint0[i, 1], endpoint1[i, 1]),\n",
    "            zorder=1, transform=fig.transFigure, c=c[i],\n",
    "            linewidth=lw) for i in range(len(l))]\n",
    "\n",
    "\n",
    "def get_flow_vis(df, ang, line_neighborhood=5):\n",
    "    norm = line_neighborhood + 1 - np.clip(df, 0, line_neighborhood)\n",
    "    flow_uv = np.stack([norm * np.cos(ang), norm * np.sin(ang)], axis=-1)\n",
    "    flow_img = flow_vis.flow_to_color(flow_uv, convert_to_bgr=False)\n",
    "    return flow_img\n",
    "\n",
    "\n",
    "def save_plot(path, **kw):\n",
    "    \"\"\"Save the current figure without any white margin.\"\"\"\n",
    "    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIDEPTH_PATH = '/cluster/courses/3dv/data/team-2/minidepth/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 950, Height: 1280\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = os.path.join(MINIDEPTH_PATH, '0000/3277894615_328d32e572_o.jpg')\n",
    "# image_path = '/home/egoedeke/Downloads/MegaDepth_v1/phoenix/S6/zl548/MegaDepth_v1/0377/dense0/imgs/138408872_2f903a81d4_o.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get dimensions\n",
    "width, height = image.size\n",
    "\n",
    "print(f\"Width: {width}, Height: {height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Unable to synchronously open file (unable to open file: name = '/home/egoedeke/OneDrive/ETH/3DVision/glue-factory/GT_lines/138408872_2f903a81d4_o.hdf5', errno = 13, error message = 'Permission denied', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open the HDF5 file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/egoedeke/OneDrive/ETH/3DVision/glue-factory/GT_lines/138408872_2f903a81d4_o.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/courses/3dv/data/team-2/3dvenv/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/cluster/courses/3dv/data/team-2/3dvenv/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Unable to synchronously open file (unable to open file: name = '/home/egoedeke/OneDrive/ETH/3DVision/glue-factory/GT_lines/138408872_2f903a81d4_o.hdf5', errno = 13, error message = 'Permission denied', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "file = h5py.File('/home/egoedeke/OneDrive/ETH/3DVision/glue-factory/GT_lines/138408872_2f903a81d4_o.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in file:  ['bg_mask', 'closest', 'df', 'line_level']\n",
      "df shape:  (1897600,)\n",
      "line_level shape:  (1897600,)\n",
      "closest shape:  (3795200,)\n",
      "bg_mask shape:  (1897600,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Keys in file: \", list(file.keys()))\n",
    "\n",
    "df = file['df'][:]\n",
    "line_level = file['line_level'][:]\n",
    "closest = file['closest'][:]\n",
    "bg_mask = file['bg_mask'][:]\n",
    "\n",
    "# print dimensions of the data\n",
    "print(\"df shape: \", df.shape)\n",
    "print(\"line_level shape: \", line_level.shape)\n",
    "print(\"closest shape: \", closest.shape)\n",
    "print(\"bg_mask shape: \", bg_mask.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/egoedeke/Downloads/MegaDepth_v1/phoenix/S6/zl548/MegaDepth_v1/0377/dense0/imgs/138408872_2f903a81d4_o.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get dimensions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# width, height = image.size\u001b[39;00m\n\u001b[1;32m      9\u001b[0m width, height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1600\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1600\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('/home/egoedeke/Downloads/MegaDepth_v1/phoenix/S6/zl548/MegaDepth_v1/0377/dense0/imgs/138408872_2f903a81d4_o.jpg')\n",
    "\n",
    "# Get dimensions\n",
    "# width, height = image.size\n",
    "\n",
    "width, height = 1600, df.shape[0] // 1600\n",
    "\n",
    "\n",
    "# width, height = 640, 480\n",
    "\n",
    "# display orginal image\n",
    "#plt.imshow(image)\n",
    "\n",
    "# Reshape the flattened arrays to the original image dimensions\n",
    "df_img = df.reshape(height, width)\n",
    "line_level_img = line_level.reshape(height, width)\n",
    "closest_img = closest.reshape(height, width, 2)  # assuming 'closest' has 2 channels\n",
    "bg_mask_img = bg_mask.reshape(height, width)\n",
    "\n",
    "print(type(line_level_img))\n",
    "\n",
    "# use def plot_images(imgs, titles=None, cmaps='gray', dpi=100, size=6, pad=.5):\n",
    "plot_images([df_img, line_level_img, closest_img[:, :, 0], bg_mask_img], \n",
    "            titles=['Distance Function Map', 'Line Level Map', 'Closest Line Map', 'Background Mask'],\n",
    "            cmaps=['gray', 'gray', 'gray', 'gray'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
